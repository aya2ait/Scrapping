name: E-commerce ML Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      skip_scraper:
        description: 'Skip data extraction step'
        required: false
        default: 'false'
        type: boolean
      skip_storage:
        description: 'Skip MongoDB storage step'
        required: false
        default: 'false'
        type: boolean
      debug_mode:
        description: 'Run with extended debugging'
        required: false
        default: 'false'
        type: boolean

env:
  PYTHON_VERSION: '3.9'
  DOCKERHUB_USERNAME: safaehm

jobs:
  ml-pipeline:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    env:
      MONGODB_VERSION: '5.0'

    services:
      mongodb:
        image: mongo:5.0
        ports:
          - 27017:27017
        options: >-
          --health-cmd "mongosh --eval 'db.adminCommand(\"ping\")'"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4

      - name: 🐍 Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: 📦 Install Docker Compose
        run: |
          sudo curl -L "https://github.com/docker/compose/releases/download/v2.20.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
          sudo chmod +x /usr/local/bin/docker-compose
          docker-compose --version

      - name: 🔧 Install Python dependencies for testing
        run: |
          python -m pip install --upgrade pip
          pip install pymongo requests

      - name: 🗂️ Setup project directories
        run: |
          mkdir -p data mlruns logs
          ls -la

      - name: 🔐 Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ env.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: 🛠️ Build and push Docker images
        run: |
          docker build -t ${{ env.DOCKERHUB_USERNAME }}/ecommerce-scraper:latest -f Dockerfile.pipelinee .
          docker build -t ${{ env.DOCKERHUB_USERNAME }}/ecommerce-storage:latest -f Dockerfile.mongo .
          docker build -t ${{ env.DOCKERHUB_USERNAME }}/ecommerce-api:latest -f Dockerfile.api .
          docker push ${{ env.DOCKERHUB_USERNAME }}/ecommerce-scraper:latest
          docker push ${{ env.DOCKERHUB_USERNAME }}/ecommerce-storage:latest
          docker push ${{ env.DOCKERHUB_USERNAME }}/ecommerce-api:latest

      - name: 🔗 Verify MongoDB connection
        run: |
          timeout 30 bash -c 'until nc -z localhost 27017; do sleep 1; done'
          python -c "
          from pymongo import MongoClient
          client = MongoClient('mongodb://localhost:27017/')
          client.admin.command('ping')
          print('✅ MongoDB is up!')
          "

      - name: 🚀 Run Pipeline with Docker Compose
        env:
          SKIP_SCRAPER: ${{ github.event.inputs.skip_scraper || 'false' }}
          SKIP_STORAGE: ${{ github.event.inputs.skip_storage || 'false' }}
        run: |
          # Create docker-compose-ci.yml
          cat > docker-compose-ci.yml << EOF
          services:
            mongodb:
              image: mongo:${{ env.MONGODB_VERSION }}
              ports:
                - 27017:27017
              volumes:
                - mongodb_data:/data/db
              healthcheck:
                test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
                interval: 10s
                timeout: 5s
                retries: 5
              networks:
                - ml-pipeline-network
            scraper:
              image: ${{ env.DOCKERHUB_USERNAME }}/ecommerce-scraper:latest
              volumes:
                - ./data:/data
                - ./logs:/app/logs
              environment:
                - MONGO_URI=mongodb://mongodb:27017/
              command: ["sh", "-c", "python3 pipeline.py && touch /data/scraper_done && ls -l /data && tail -f /app/logs/unified_extraction_pipeline.log"]
              healthcheck:
                test: ["CMD", "test", "-f", "/data/scraper_done"]
                interval: 10s
                timeout: 5s
                retries: 180
              networks:
                - ml-pipeline-network
            storage:
              image: ${{ env.DOCKERHUB_USERNAME }}/ecommerce-storage:latest
              depends_on:
                mongodb:
                  condition: service_healthy
                scraper:
                  condition: service_healthy
              volumes:
                - ./data:/data
                - ./logs:/app/logs
              environment:
                - MONGO_URI=mongodb://mongodb:27017/
                - MONGODB_DATABASE=products_db
                - MONGODB_COLLECTION=products
              command: ["sh", "-c", "ls -l /data && python mongo.py /data/unified_extracted_products.csv >> /app/logs/storage.log 2>&1 && touch /data/storage_done && sleep infinity || echo 'mongo.py failed' >> /app/logs/storage.log"]
              healthcheck:
                test: ["CMD", "test", "-f", "/data/storage_done"]
                interval: 10s
                timeout: 5s
                retries: 60
              networks:
                - ml-pipeline-network
            api:
              image: ${{ env.DOCKERHUB_USERNAME }}/ecommerce-api:latest
              depends_on:
                storage:
                  condition: service_healthy
              ports:
                - "5000:5000"
              volumes:
                - ./data:/data
                - ./mlruns:/app/mlruns
              environment:
                - MONGO_URI=mongodb://mongodb:27017/
                - MONGODB_DATABASE=products_db
                - MONGODB_COLLECTION=products
              networks:
                - ml-pipeline-network
          networks:
            ml-pipeline-network:
              driver: bridge
          volumes:
            mongodb_data:
          EOF
          # Run services conditionally
          if [ "$SKIP_SCRAPER" = "true" ]; then
            sed -i "/scraper:/,/^\s*networks:/d" docker-compose-ci.yml
          fi
          if [ "$SKIP_STORAGE" = "true" ]; then
            sed -i "/storage:/,/^\s*networks:/d" docker-compose-ci.yml
          fi
          cat docker-compose-ci.yml
          docker-compose -f docker-compose-ci.yml up -d
          
          # Show initial container status
          docker-compose -f docker-compose-ci.yml ps
          
          # Wait for scraper to complete (max 5 minutes)
          echo "Waiting for scraper to complete..."
          timeout 300 bash -c 'until test -f data/scraper_done || docker-compose -f docker-compose-ci.yml logs scraper | grep -q "Error"; do echo "."; sleep 10; done'
          
          # Show scraper logs
          echo "=== Scraper Logs ==="
          docker-compose -f docker-compose-ci.yml logs scraper | tail -n 30
          
          # Wait for storage to complete (max 2 minutes)
          echo "Waiting for storage to complete..."
          timeout 120 bash -c 'until test -f data/storage_done || docker-compose -f docker-compose-ci.yml logs storage | grep -q "failed"; do echo "."; sleep 10; done'
          
          # Show storage logs
          echo "=== Storage Logs ==="
          docker-compose -f docker-compose-ci.yml logs storage | tail -n 30
          
          # Show all logs if in debug mode
          if [ "${{ github.event.inputs.debug_mode }}" = "true" ]; then
            echo "=== All Container Logs ==="
            docker-compose -f docker-compose-ci.yml logs
          fi
          
          # Keep containers running for testing
          sleep 60
          
          # Cleanup
          docker-compose -f docker-compose-ci.yml down

      - name: 🕵️ Debug Pipeline Status
        continue-on-error: true
        run: |
          echo "=== Checking for CSV file ==="
          ls -la data/
          if [ -f data/unified_extracted_products.csv ]; then
            echo "CSV file exists, checking content:"
            wc -l data/unified_extracted_products.csv
            head -n 2 data/unified_extracted_products.csv
          else
            echo "CSV file not found!"
          fi
          
          echo "=== Checking logs ==="
          if [ -f logs/unified_extraction_pipeline.log ]; then
            echo "=== Scraper Log ==="
            tail -n 20 logs/unified_extraction_pipeline.log
          fi
          if [ -f logs/storage.log ]; then
            echo "=== Storage Log ==="
            tail -n 20 logs/storage.log
          fi
          
          echo "=== Checking MongoDB ==="
          python -c "
          from pymongo import MongoClient
          client = MongoClient('mongodb://localhost:27017/')
          print('Available databases:', client.list_database_names())
          if 'products_db' in client.list_database_names():
              db = client['products_db']
              collections = db.list_collection_names()
              print('Collections in products_db:', collections)
              if 'products' in collections:
                  count = db['products'].count_documents({})
                  print(f'Products count: {count}')
                  if count > 0:
                      sample = db['products'].find_one()
                      print(f'Sample document: {sample}')
                  else:
                      print('No products found in collection')
              else:
                  print('Products collection not found')
          else:
              print('Products_db database not found')
          "

      - name: 📊 Validate pipeline outputs
        continue-on-error: true
        run: |
          if [ -f data/unified_extracted_products.csv ]; then
            echo "✅ Data CSV found:"
            wc -l data/unified_extracted_products.csv
            head -n 5 data/unified_extracted_products.csv
            lines=$(wc -l < data/unified_extracted_products.csv)
            if [ "$lines" -ge 1 ]; then
              echo "✅ Found $lines products"
            else
              echo "⚠️ CSV file exists but appears empty"
            fi
          else
            echo "⚠️ No CSV file found"
          fi

      - name: 🧪 Test API endpoints
        continue-on-error: true
        run: |
          echo "Testing API health endpoint..."
          curl -v http://localhost:5000/health || echo "⚠️ API health check failed"
          
          echo "Testing API database-stats endpoint..."
          curl -v http://localhost:5000/api/database-stats || echo "⚠️ API database-stats failed"
          
          echo "Testing API top-k-products endpoint..."
          curl -v -X POST http://localhost:5000/api/top-k-products -H "Content-Type: application/json" -d '{"k": 5, "criteria": "price"}' || echo "⚠️ API top-k-products failed"

      - name: 📦 Upload Artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: logs-and-data
          path: |
            data/
            logs/